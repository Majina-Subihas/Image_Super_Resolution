{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace8e197",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import torchmetrics\n",
    "\n",
    "# Dataset\n",
    "class SuperResolutionDataset(Dataset):\n",
    "    def __init__(self, low_res_dir, high_res_dir, subset_size=None):\n",
    "        self.low_res_dir = low_res_dir\n",
    "        self.high_res_dir = high_res_dir\n",
    "        self.low_res_images = sorted(os.listdir(low_res_dir))\n",
    "        self.high_res_images = sorted(os.listdir(high_res_dir))\n",
    "        if subset_size:\n",
    "            self.low_res_images = self.low_res_images[:subset_size]\n",
    "            self.high_res_images = self.high_res_images[:subset_size]\n",
    "        self.transform = transforms.ToTensor()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.low_res_images)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        low_res = Image.open(os.path.join(self.low_res_dir, self.low_res_images[index])).convert(\"RGB\")\n",
    "        high_res = Image.open(os.path.join(self.high_res_dir, self.high_res_images[index])).convert(\"RGB\")\n",
    "        return self.transform(low_res), self.transform(high_res)\n",
    "\n",
    "\n",
    "# Shallow Feature Extractor\n",
    "class ShallowFeatureExtractor(nn.Module):\n",
    "    def __init__(self, in_channels=3, out_channels=64):\n",
    "        super().__init__()\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, 3, 1, 1),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.head(x)\n",
    "\n",
    "# CRRB\n",
    "class CRRB(nn.Module):\n",
    "    def __init__(self, channels):\n",
    "        super().__init__()\n",
    "        self.conv_high = nn.Sequential(\n",
    "            nn.Conv2d(channels, channels, 3, 1, 1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(channels, channels, 3, 1, 1)\n",
    "        )\n",
    "        self.downsample = nn.Conv2d(channels, channels, 4, 2, 1)\n",
    "        self.upsample = nn.ConvTranspose2d(channels, channels, 4, 2, 1)\n",
    "        self.conv_low = nn.Sequential(\n",
    "            nn.Conv2d(channels, channels, 3, 1, 1),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, f_high, f_low):\n",
    "        high_feat = self.conv_high(f_high)\n",
    "\n",
    "        # Save original size of f_high\n",
    "        target_size = high_feat.shape[2:]\n",
    "\n",
    "        # Pad f_low so it's divisible by 2 before downsampling\n",
    "        h, w = f_low.shape[2], f_low.shape[3]\n",
    "        pad_h = (2 - h % 2) % 2\n",
    "        pad_w = (2 - w % 2) % 2\n",
    "        f_low_padded = F.pad(f_low, (0, pad_w, 0, pad_h), mode='reflect')\n",
    "\n",
    "        # Downsample and upsample\n",
    "        low_down = self.downsample(f_low_padded)\n",
    "        low_feat = self.upsample(self.conv_low(low_down))\n",
    "\n",
    "        # Final: match exactly to f_high size\n",
    "        low_feat = F.interpolate(low_feat, size=target_size, mode='bilinear', align_corners=False)\n",
    "\n",
    "        return high_feat + low_feat\n",
    "\n",
    "\n",
    "\n",
    "# RAB\n",
    "class RAB(nn.Module):\n",
    "    def __init__(self, channels):\n",
    "        super().__init__()\n",
    "        self.pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Conv2d(channels * 2, channels // 2, 1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(channels // 2, channels * 2, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, f1, f2): \n",
    "        f2 = F.interpolate(f2, size=f1.shape[2:], mode='bilinear', align_corners=False)\n",
    "        fused = torch.cat([f1, f2], dim=1)\n",
    "        weights = self.fc(self.pool(fused))\n",
    "        w1, w2 = torch.chunk(weights, 2, dim=1)\n",
    "        return f1 * w1 + f2 * w2\n",
    "\n",
    "# CRFAN Model\n",
    "class CRFAN(nn.Module):\n",
    "    def __init__(self, in_channels=3, out_channels=3, num_features=64):\n",
    "        super().__init__()\n",
    "        self.shallow_feat = ShallowFeatureExtractor(in_channels, num_features)\n",
    "\n",
    "        self.up2 = nn.ConvTranspose2d(num_features, num_features, 4, 2, 1)\n",
    "        self.crrb2 = nn.Sequential(*[CRRB(num_features) for _ in range(4)])\n",
    "\n",
    "        self.up4 = nn.ConvTranspose2d(num_features, num_features, 4, 2, 1)\n",
    "        self.crrb4 = nn.Sequential(*[CRRB(num_features) for _ in range(2)])\n",
    "\n",
    "        self.up8 = nn.ConvTranspose2d(num_features, num_features, 4, 2, 1)\n",
    "        self.crrb8 = CRRB(num_features)\n",
    "\n",
    "        self.rab1 = RAB(num_features)\n",
    "        self.rab2 = RAB(num_features)\n",
    "        self.reconstruct = nn.Conv2d(num_features, out_channels, 3, 1, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.shallow_feat(x)\n",
    "\n",
    "        x2 = self.up2(x1)\n",
    "        for block in self.crrb2:\n",
    "            x2 = block(x2, x1)\n",
    "\n",
    "        x4 = self.up4(x2)\n",
    "        for block in self.crrb4:\n",
    "            x4 = block(x4, x2)\n",
    "\n",
    "        x8 = self.up8(x4)\n",
    "        x8 = self.crrb8(x8, x4)\n",
    "\n",
    "        fuse1 = self.rab1(x4, x2)\n",
    "        fuse2 = self.rab2(x8, fuse1)\n",
    "\n",
    "        out = self.reconstruct(fuse2)\n",
    "\n",
    "        # Residual connection with input upsampled Ã—8\n",
    "        input_upsampled = F.interpolate(x, size=out.shape[2:], mode='bicubic', align_corners=False)\n",
    "        return out + input_upsampled\n",
    "\n",
    "# Training\n",
    "def train_model(model, dataloader, num_epochs=10, lr=1e-5, device='cuda', accumulation_steps=4):\n",
    "    optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=lr)\n",
    "    scaler = torch.cuda.amp.GradScaler()\n",
    "    ssim_metric = torchmetrics.StructuralSimilarityIndexMeasure(data_range=1.0).to(device)\n",
    "    \n",
    "    criterion = nn.MSELoss().to(device)\n",
    "\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "    best_psnr = 0.0\n",
    "    best_epoch = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_loss, epoch_psnr, epoch_ssim = 0, 0, 0\n",
    "        optimizer.zero_grad()\n",
    "        pbar = tqdm(dataloader, desc=f\"Epoch {epoch+1}/{num_epochs}\", ncols=100)\n",
    "\n",
    "        for step, (lr_img, hr_img) in enumerate(pbar):\n",
    "            lr_img, hr_img = lr_img.to(device), hr_img.to(device)\n",
    "\n",
    "            with torch.cuda.amp.autocast():\n",
    "                out = model(lr_img)\n",
    "                out_resized = F.interpolate(out, size=hr_img.shape[2:], mode='bicubic')\n",
    "                loss = criterion(out_resized, hr_img)\n",
    "                mse = F.mse_loss(out_resized, hr_img)\n",
    "                psnr = 10 * torch.log10(1.0 / mse)\n",
    "                ssim_val = ssim_metric(out_resized, hr_img)\n",
    "\n",
    "            scaler.scale(loss).backward()\n",
    "\n",
    "            if (step + 1) % accumulation_steps == 0 or (step + 1) == len(dataloader):\n",
    "                scaler.unscale_(optimizer)\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_psnr += psnr.item()\n",
    "            epoch_ssim += ssim_val.item()\n",
    "\n",
    "            pbar.set_postfix({\n",
    "                \"Loss\": f\"{epoch_loss / (step + 1):.4f}\",\n",
    "                \"PSNR\": f\"{epoch_psnr / (step + 1):.2f}\",\n",
    "                \"SSIM\": f\"{epoch_ssim / (step + 1):.4f}\"\n",
    "            })\n",
    "\n",
    "        avg_psnr = epoch_psnr / len(dataloader)\n",
    "        if avg_psnr > best_psnr:\n",
    "            best_psnr = avg_psnr\n",
    "            best_epoch = epoch + 1\n",
    "            torch.save(model.state_dict(), \"crfan_best_model.pth\")\n",
    "            print(f\"\\nðŸ“¦ Best model saved at epoch {best_epoch} with PSNR: {best_psnr:.2f} dB\")\n",
    "\n",
    "    torch.save(model.state_dict(), \"crfan_model_last_epoch.pth\")\n",
    "    print(\"\\nâœ… Final model saved as crfan_model_last_epoch.pth\")\n",
    "\n",
    "# Main\n",
    "if __name__ == \"__main__\":\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "    low_res_path = \"/home/serenag/super_resolution/CalebA/lr_downsampled_images\"\n",
    "    high_res_path = \"/home/serenag/super_resolution/CalebA/hr_upsampled_images\"\n",
    "\n",
    "    dataset = SuperResolutionDataset(low_res_path, high_res_path)\n",
    "    dataloader = DataLoader(dataset, batch_size=2, shuffle=True, num_workers=4, pin_memory=True)\n",
    "\n",
    "    model = CRFAN()\n",
    "    train_model(model, dataloader, num_epochs=10, lr=1e-5)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (serenv)",
   "language": "python",
   "name": "serenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
